{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCSt2x-sTu0C"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from datetime import datetime\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the dataset\n",
        "energy_data = pd.read_csv('energy_weather101.csv')\n",
        "\n",
        "# Check the shape of the dataset\n",
        "print(energy_data.shape)\n",
        "\n",
        "\"\"\"## Data Exploration\"\"\"\n",
        "\n",
        "print(\"Displaying the first 5 rows\",\"\\n\")\n",
        "print(energy_data.head())\n",
        "\n",
        "print(\"Displaying the last 5 rows\",\"\\n\")\n",
        "print(energy_data.tail())\n",
        "\n",
        "print(\"Get info on the dataset\")\n",
        "energy_data.info()\n",
        "\n",
        "print(\"Descriptive statistics\",\"\\n\")\n",
        "print(energy_data.describe(), \"\\n\")\n",
        "\n",
        "# Check for null values\n",
        "print(\"Columns with null values\",\"\\n\")\n",
        "print(energy_data.isnull().sum())\n",
        "\n",
        "# Remove unnecessary columns\n",
        "energy_data.drop(['generation hydro pumped storage aggregated','forecast wind offshore eday ahead'], axis=1, inplace=True)\n",
        "\n",
        "# Replace null values with column means\n",
        "energy_data.fillna(energy_data.mean(), inplace=True)\n",
        "\n",
        "# Feature Selection\n",
        "\n",
        "# Delete columns starting with 'generation'\n",
        "energy_data.drop(energy_data.filter(regex='generation'), axis=1, inplace=True)\n",
        "\n",
        "# Remove specific columns\n",
        "energy_data.drop(['rain_1h','rain_3h','snow_3h','clouds_all'], axis=1, inplace=True)\n",
        "\n",
        "# Check for nan values\n",
        "print(\"Columns with null values after processing\",\"\\n\")\n",
        "print(energy_data.isnull().sum())\n",
        "\n",
        "# Replace unique items in 'weather_main' with numbers\n",
        "unique_weather_main = energy_data['weather_main'].unique()\n",
        "weather_main_ranks = pd.Series(range(1, len(unique_weather_main)+1), index=unique_weather_main)\n",
        "energy_data['weather_main'] = energy_data['weather_main'].map(weather_main_ranks)\n",
        "\n",
        "# Remove 'weather_description' and 'weather_icon' columns\n",
        "energy_data.drop(['weather_description', 'weather_icon'], axis=1, inplace=True)\n",
        "\n",
        "# Remove columns irrelevant to analysis\n",
        "energy_data.drop(['forecast solar day ahead', 'forecast wind onshore day ahead', 'total load forecast', 'price day ahead', 'price actual', 'city_name'], axis=1, inplace=True)\n",
        "\n",
        "# Data Visualization\n",
        "\n",
        "# Calculate autocorrelation\n",
        "lags = np.arange(1, 24 * 10 + 1)\n",
        "autocorrelation = [energy_data['total load actual'].autocorr(lag=l) for l in lags]\n",
        "\n",
        "# Plot autocorrelation\n",
        "plt.figure()\n",
        "plt.plot(lags, autocorrelation)\n",
        "plt.xlabel(\"Lag\")\n",
        "plt.ylabel(\"Autocorrelation\")\n",
        "plt.title(\"Autocorrelation of Actual Total Load\")\n",
        "plt.show()\n",
        "\n",
        "# Plot demand against time of year\n",
        "plt.scatter(energy_data['TimeOfYear'], energy_data['total load actual'], s=1)\n",
        "plt.xlabel('Time of Year')\n",
        "plt.ylabel('Demand')\n",
        "plt.title('Demand vs Time of Year')\n",
        "plt.show()\n",
        "\n",
        "# Plot average demand by month\n",
        "energy_data['Month'] = energy_data.index.month\n",
        "energy_data.groupby('Month')['total load actual'].mean().plot(kind='bar')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Demand (MW)')\n",
        "plt.title('Average Demand by Month (2015-2019)')\n",
        "plt.show()\n",
        "\n",
        "# For each hour of the day, calculate and plot average demand\n",
        "energy_data['Hour'] = energy_data.index.hour\n",
        "energy_data.groupby('Hour')['total load actual'].mean().plot(kind='bar')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Average Demand (MW)')\n",
        "plt.title('Average Demand by Hour (2015-2019)')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = energy_data.drop(['total load actual', 'date'], axis=1)\n",
        "y = energy_data['total load actual']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Linear Regression\n",
        "lm = LinearRegression()\n",
        "lm.fit(X_train, y_train)\n",
        "lm_error = mean_squared_error(y_test, lm.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=200, random_state=1)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_error = mean_squared_error(y_test, rf.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "gb = GradientBoostingRegressor(n_estimators=200, random_state=1)\n",
        "gb.fit(X_train, y_train)\n",
        "gb_error = mean_squared_error(y_test, gb.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# Support Vector Regression\n",
        "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
        "svr.fit(X_train, y_train)\n",
        "svr_error = mean_squared_error(y_test, svr.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# Neural Networks\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=500, alpha=0.0001, solver='adam', random_state=21)\n",
        "mlp.fit(X_train, y_train)\n",
        "mlp_error = mean_squared_error(y_test, mlp.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBRegressor(n_estimators=200, random_state=1)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_error = mean_squared_error(y_test, xgb.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# CatBoost\n",
        "cat = CatBoostRegressor(n_estimators=200, random_state=1)\n",
        "cat.fit(X_train, y_train)\n",
        "cat_error = mean_squared_error(y_test, cat.predict(X_test)) / np.mean(y_test)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=10)\n",
        "pca.fit(X_train)\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Random Forest with PCA\n",
        "rf_pca = RandomForestRegressor(n_estimators=200, random_state=1)\n",
        "rf_pca.fit(X_train_pca, y_train)\n",
        "rf_pca_error = mean_squared_error(y_test, rf_pca.predict(X_test_pca)) / np.mean(y_test)\n",
        "\n",
        "# XGBoost with PCA\n",
        "xgb_pca = XGBRegressor(n_estimators=200, random_state=1)\n",
        "xgb_pca.fit(X_train_pca, y_train)\n",
        "xgb_pca_error = mean_squared_error(y_test, xgb_pca.predict(X_test_pca)) / np.mean(y_test)\n",
        "\n",
        "# Plotting the errors of different models\n",
        "errors = [lm_error, rf_error, cat_error, gb_error, mlp_error, svr_error, xgb_error]\n",
        "models = ['Linear Regression', 'Random Forest', 'CatBoost', 'Gradient Boosting', 'Neural Networks', 'Support Vector Regression', 'XGBoost']\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(models, errors)\n",
        "plt.xticks(rotation=270)\n",
        "plt.title('Mean Squared Error of Each Model')\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sVADr7lnT1Wq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}